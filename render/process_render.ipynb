{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/mnt/data2/code/opensource/2d-gaussian-splatting/render/renderings_fix_lighting\"\n",
    "depth_scale = 1000.0\n",
    "cases = [\"sony\", \"helmet\", \"marci\", \"miyuki\", \"pigeon\", \"pine_cone\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in cases:\n",
    "    if not os.path.isdir(os.path.join(base_dir, case)):\n",
    "        continue\n",
    "    os.makedirs(os.path.join(base_dir, case, \"images\"), exist_ok=True)\n",
    "    images = os.listdir(os.path.join(base_dir, case))\n",
    "    for img_name in tqdm(images):\n",
    "        if \"normal0000\" in img_name or \"depth0000\" in img_name or \"mask0000\" in img_name:\n",
    "            basename, ext = os.path.splitext(img_name)\n",
    "            os.rename(\n",
    "                os.path.join(base_dir, case, img_name),\n",
    "                os.path.join(base_dir, case, \"images\", basename[:-4] + ext),\n",
    "            )\n",
    "            # print(f\"Renamd {img_name} to images/{basename[:-4] + ext}\")\n",
    "        elif img_name.endswith(\"png\"):\n",
    "            img = Image.open(os.path.join(base_dir, case, img_name))\n",
    "            img = img.convert(\"RGB\")\n",
    "            img.save(os.path.join(base_dir, case, \"images\", img_name.replace(\"png\", \"jpg\")))\n",
    "            os.rename(os.path.join(base_dir, case, img_name), os.path.join(base_dir, case, \"images\", img_name))\n",
    "        elif img_name.endswith(\"exr\") and not \"vis\" in img_name:\n",
    "            img = imageio.imread(os.path.join(base_dir, case, img_name))\n",
    "            img = img[..., :3]\n",
    "            imageio.imsave(os.path.join(base_dir, case, img_name.replace(\".exr\", \"_vis.exr\")), img)\n",
    "        # print(f\"Skipping {im}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in cases:\n",
    "    if not os.path.isdir(os.path.join(base_dir, case)):\n",
    "        continue\n",
    "    depth_imgs = [im for im in os.listdir(os.path.join(base_dir, case, \"images\")) if \"depth.exr\" in im]\n",
    "    for d_name in tqdm(depth_imgs):\n",
    "        d_im = imageio.imread(os.path.join(base_dir, case, \"images\", d_name))\n",
    "        m_name = d_name.replace(\"depth.exr\", \"mask.png\")\n",
    "        m_im = imageio.imread(os.path.join(base_dir, case, \"images\", m_name))\n",
    "        m_im = (m_im[..., None] / 255.0).astype(np.float32)\n",
    "        d_im = d_im * m_im\n",
    "        \n",
    "        d_im = (d_im * depth_scale)[..., 0].astype(np.uint16)\n",
    "        \n",
    "        imageio.imwrite(os.path.join(base_dir, case, \"images\", d_name.replace(\"exr\", \"png\")), d_im, extension=\"png\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(meta, train_ratio=0.6, val_ratio=0.2):\n",
    "    meta_train, meta_val, meta_test = {}, {}, {}\n",
    "    for key, value in meta.items():\n",
    "        if key.startswith(\"frames\"):\n",
    "            frames = meta[\"frames\"]\n",
    "            for frame in frames:\n",
    "                frame[\"file_path\"] = \"images/\" + frame[\"file_path\"]\n",
    "            num_frames = len(frames)\n",
    "            num_train = int(num_frames * train_ratio)\n",
    "            num_val = int(num_frames * val_ratio)\n",
    "            idx = np.random.permutation(num_frames)\n",
    "            meta_train[\"frames\"] = [frames[i] for i in idx[:num_train]]\n",
    "            meta_val[\"frames\"] = [frames[i] for i in idx[num_train : num_train + num_val]]\n",
    "            meta_test[\"frames\"] = [frames[i] for i in idx[num_train + num_val :]]\n",
    "        else:\n",
    "            meta_train[key] = value\n",
    "            meta_val[key] = value\n",
    "            meta_test[key] = value\n",
    "    return meta_train, meta_val, meta_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in cases:\n",
    "    if not os.path.isdir(os.path.join(base_dir, case)):\n",
    "        continue\n",
    "    with open(os.path.join(base_dir, case, \"transforms.json\"), \"r\") as f:\n",
    "        meta = json.load(f)\n",
    "    meta_train, meta_val, meta_test = split_dataset(meta)\n",
    "    \n",
    "    \n",
    "    with open(os.path.join(base_dir, case, \"transforms_train.json\"), \"w\") as f:\n",
    "        json.dump(meta_train, f, indent=4)\n",
    "\n",
    "    with open(os.path.join(base_dir, case, \"transforms_val.json\"), \"w\") as f:\n",
    "        json.dump(meta_val, f, indent=4)\n",
    "        \n",
    "    with open(os.path.join(base_dir, case, \"transforms_test.json\"), \"w\") as f:\n",
    "        json.dump(meta_test, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from arguments import ModelParams\n",
    "from eval_metrics_rotblender import get_mesh_eval_points\n",
    "from scene.gaussian_model import GaussianModel\n",
    "from argparse import ArgumentParser, Namespace\n",
    "\n",
    "from scene import Scene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found transforms_train.json file, assuming Blender data set!\n",
      "Reading Training Transforms\n",
      "Reading Test Transforms\n",
      "Loading Training Cameras\n",
      "Loading Test Cameras\n",
      "Number of points at initialisation :  100000\n",
      "Running tsdf volume integration ...\n",
      "voxel_size: 0.002\n",
      "sdf_trunc: 0.01\n",
      "depth_truc: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TSDF integration progress: 14it [00:01, 13.05it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [1, 800, 800] at index 1 does not match the shape of the indexed tensor [1, 1024, 2048] at index 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m gaussians \u001b[38;5;241m=\u001b[39m GaussianModel(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m scene \u001b[38;5;241m=\u001b[39m Scene(cfg, gaussians, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 18\u001b[0m \u001b[43mget_mesh_eval_points\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscene\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcase\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data2/code/opensource/2d-gaussian-splatting/eval_metrics_rotblender.py:51\u001b[0m, in \u001b[0;36mget_mesh_eval_points\u001b[0;34m(scene, source_dir)\u001b[0m\n\u001b[1;32m     48\u001b[0m     rgbs\u001b[38;5;241m.\u001b[39mappend(rgb)\n\u001b[1;32m     49\u001b[0m     depths\u001b[38;5;241m.\u001b[39mappend(depth)\n\u001b[0;32m---> 51\u001b[0m mesh \u001b[38;5;241m=\u001b[39m \u001b[43mtsdf_integration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mviewpoints\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrgbs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoxel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.002\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msdf_trunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdepth_trunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m eval_pcd \u001b[38;5;241m=\u001b[39m mesh\u001b[38;5;241m.\u001b[39msample_points_poisson_disk(number_of_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100_000\u001b[39m)\n\u001b[1;32m     54\u001b[0m o3d\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mwrite_point_cloud((source_dir \u001b[38;5;241m/\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meval_points.ply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mas_posix(), eval_pcd)\n",
      "File \u001b[0;32m/mnt/data2/code/opensource/2d-gaussian-splatting/utils/mesh_utils.py:94\u001b[0m, in \u001b[0;36mtsdf_integration\u001b[0;34m(viewpoints, rgbs, depths, voxel_size, sdf_trunc, depth_trunc, mask_background)\u001b[0m\n\u001b[1;32m     91\u001b[0m depth \u001b[38;5;241m=\u001b[39m depths[i]\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask_background \u001b[38;5;129;01mand\u001b[39;00m (viewpoints[i]\u001b[38;5;241m.\u001b[39mgt_alpha_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m---> 94\u001b[0m     \u001b[43mdepth\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mviewpoints\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgt_alpha_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m<\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     96\u001b[0m rgbd \u001b[38;5;241m=\u001b[39m o3d\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mRGBDImage\u001b[38;5;241m.\u001b[39mcreate_from_color_and_depth(\n\u001b[1;32m     97\u001b[0m     o3d\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mImage(np\u001b[38;5;241m.\u001b[39masarray(rgb\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy() \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m255\u001b[39m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)),\n\u001b[1;32m     98\u001b[0m     o3d\u001b[38;5;241m.\u001b[39mgeometry\u001b[38;5;241m.\u001b[39mImage(np\u001b[38;5;241m.\u001b[39masarray(depth\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy(), order\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC\u001b[39m\u001b[38;5;124m\"\u001b[39m)),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    101\u001b[0m     depth_scale\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m,\n\u001b[1;32m    102\u001b[0m )\n\u001b[1;32m    104\u001b[0m volume\u001b[38;5;241m.\u001b[39mintegrate(rgbd, intrinsic\u001b[38;5;241m=\u001b[39mcam_o3d\u001b[38;5;241m.\u001b[39mintrinsic, extrinsic\u001b[38;5;241m=\u001b[39mcam_o3d\u001b[38;5;241m.\u001b[39mextrinsic)\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [1, 800, 800] at index 1 does not match the shape of the indexed tensor [1, 1024, 2048] at index 1"
     ]
    }
   ],
   "source": [
    "for case in cases:\n",
    "    cfg = {\n",
    "        \"model_path\": \"\",\n",
    "        \"source_path\": os.path.join(base_dir, case),\n",
    "        \"white_background\": True,\n",
    "        \"eval\": False,\n",
    "        \"rotation\": True,\n",
    "        \"apply_mask\": False,\n",
    "        \"linear\": False,\n",
    "        \"shuffle\": False,\n",
    "        \"resolution\": 1,\n",
    "        \"data_device\": \"cuda\"\n",
    "    }\n",
    "    cfg = Namespace(**cfg)\n",
    "    gaussians = GaussianModel(3, -1, None, None)\n",
    "    scene = Scene(cfg, gaussians, shuffle=False)\n",
    "\n",
    "    get_mesh_eval_points(scene, source_dir=os.path.join(base_dir, case))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "threestudio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
